{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data augmentation & Using float16 mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/workspace/data2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# NeMo's \"core\" package\n",
    "import nemo\n",
    "# NeMo's ASR collection\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our NeuralModuleFactory, which will oversee the neural modules.\n",
    "nf = nemo.core.NeuralModuleFactory(\n",
    "    optimization_level=nemo.core.Optimization.mxprO1, # tensorcores kicks in to do fast matrix multiplication in float16 mode\n",
    "    cudnn_benchmark=True)\n",
    "\n",
    "logger = nemo.logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config Information ---#\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "config_path = 'jasper_an4.yaml'\n",
    "\n",
    "yaml = YAML(typ='safe')\n",
    "with open(config_path) as f:\n",
    "    params = yaml.load(f)\n",
    "labels = params['labels'] # Vocab\n",
    "\n",
    "train_manifest = 'train_manifest.json'\n",
    "test_manifest = 'test_manifest.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Neural Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test data layers (which load data) and data preprocessor\n",
    "data_layer_train = nemo_asr.AudioToTextDataLayer.import_from_config(\n",
    "    config_path,\n",
    "    \"AudioToTextDataLayer_train\",\n",
    "    overwrite_params={\"manifest_filepath\": train_manifest}\n",
    ") # Training datalayer\n",
    "\n",
    "data_layer_test = nemo_asr.AudioToTextDataLayer.import_from_config(\n",
    "    config_path,\n",
    "    \"AudioToTextDataLayer_eval\",\n",
    "    overwrite_params={\"manifest_filepath\": test_manifest}\n",
    ") # Eval datalayer\n",
    "\n",
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor.import_from_config(\n",
    "    config_path, \"AudioToMelSpectrogramPreprocessor\"\n",
    ")\n",
    "\n",
    "# Create the Jasper_4x1 encoder as specified, and a CTC decoder\n",
    "encoder = nemo_asr.JasperEncoder.import_from_config(\n",
    "    config_path, \"JasperEncoder\"\n",
    ")\n",
    "\n",
    "decoder = nemo_asr.JasperDecoderForCTC.import_from_config(\n",
    "    config_path, \"JasperDecoderForCTC\",\n",
    "    overwrite_params={\"num_classes\": len(labels)}\n",
    ")\n",
    "\n",
    "ctc_loss = nemo_asr.CTCLossNM(num_classes=len(labels))\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assemble Training DAG --- #\n",
    "audio_signal, audio_signal_len, transcript, transcript_len = data_layer_train()\n",
    "\n",
    "processed_signal, processed_signal_len = data_preprocessor(\n",
    "    input_signal=audio_signal,\n",
    "    length=audio_signal_len)\n",
    "\n",
    "############## This is the only part that's changed! ##############\n",
    "# Create a SpectrogramAugmentation module\n",
    "spectrogram_aug = nemo_asr.SpectrogramAugmentation(\n",
    "    rect_masks=5, rect_time=120, rect_freq=50)\n",
    "\n",
    "processed_signal_aug = spectrogram_aug(input_spec=processed_signal)\n",
    "\n",
    "encoded, encoded_len = encoder(\n",
    "    audio_signal=processed_signal_aug,  # Change this argument too\n",
    "    length=processed_signal_len)\n",
    "###################################################################\n",
    "\n",
    "log_probs = decoder(encoder_output=encoded)\n",
    "\n",
    "loss = ctc_loss(\n",
    "    log_probs=log_probs,\n",
    "    targets=transcript,\n",
    "    input_length=encoded_len,\n",
    "    target_length=transcript_len)\n",
    "\n",
    "preds = greedy_decoder(log_probs=log_probs)  # Training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assemble Validation DAG --- #\n",
    "(audio_signal_test, audio_len_test,\n",
    " transcript_test, transcript_len_test) = data_layer_test()\n",
    "\n",
    "processed_signal_test, processed_len_test = data_preprocessor(\n",
    "    input_signal=audio_signal_test,\n",
    "    length=audio_len_test)\n",
    "\n",
    "encoded_test, encoded_len_test = encoder(\n",
    "    audio_signal=processed_signal_test,\n",
    "    length=processed_len_test)\n",
    "\n",
    "log_probs_test = decoder(encoder_output=encoded_test)\n",
    "preds_test = greedy_decoder(log_probs=log_probs_test)  # Test predictions\n",
    "loss_test = ctc_loss(\n",
    "    log_probs=log_probs_test,\n",
    "    targets=transcript_test,\n",
    "    input_length=encoded_len_test,\n",
    "    target_length=transcript_len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use these imports to pass to callbacks more complex functions to perform.\n",
    "from nemo.collections.asr.helpers import monitor_asr_train_progress, \\\n",
    "    process_evaluation_batch, process_evaluation_epoch\n",
    "from functools import partial\n",
    "\n",
    "train_callback = nemo.core.SimpleLossLoggerCallback(\n",
    "    # Notice that we pass in loss, predictions, and the transcript info.\n",
    "    # Of course we would like to see our training loss, but we need the\n",
    "    # other arguments to calculate the WER.\n",
    "    tensors=[loss, preds, transcript, transcript_len],\n",
    "    # The print_func defines what gets printed.\n",
    "    print_func=partial(\n",
    "        monitor_asr_train_progress,\n",
    "        labels=labels),\n",
    "    )\n",
    "\n",
    "# We can create as many evaluation DAGs and callbacks as we want,\n",
    "# which is useful in the case of having more than one evaluation dataset.\n",
    "# In this case, we only have one.\n",
    "eval_callback = nemo.core.EvaluatorCallback(\n",
    "    eval_tensors=[loss_test, preds_test, transcript_test, transcript_len_test],\n",
    "    user_iter_callback=partial(\n",
    "        process_evaluation_batch, labels=labels),\n",
    "    user_epochs_done_callback=process_evaluation_epoch,\n",
    "    eval_step=500,  # How often we evaluate the model on the test set\n",
    "    )\n",
    "\n",
    "checkpoint_saver_callback = nemo.core.CheckpointCallback(\n",
    "    folder=data_dir+'/an4_checkpoints2',\n",
    "    step_freq=1000  # How often checkpoints are saved\n",
    "    )\n",
    "\n",
    "import os\n",
    "if not os.path.exists(data_dir+'/an4_checkpoints2'):\n",
    "    os.makedirs(data_dir+'/an4_checkpoints2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Start Training! --- #\n",
    "nf.train(\n",
    "    tensors_to_optimize=[loss],\n",
    "    callbacks=[train_callback, eval_callback, checkpoint_saver_callback],\n",
    "    optimizer='novograd',\n",
    "    optimization_params={\n",
    "        \"num_epochs\": 110, \"lr\": 0.001, \"weight_decay\": 1e-4 # already run 100 epochs and here we do another 10\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference Only --- #\n",
    "\n",
    "# We've already built the inference DAG above, so all we need is to call infer().\n",
    "evaluated_tensors = nf.infer(\n",
    "    # These are the tensors we want to get from the model.\n",
    "    tensors=[loss_test, preds_test, transcript_test, transcript_len_test],\n",
    "    # checkpoint_dir specifies where the model params are loaded from.\n",
    "    checkpoint_dir=(data_dir+'/an4_checkpoints2')\n",
    "    )\n",
    "\n",
    "# Process the results to get WER\n",
    "from nemo.collections.asr.helpers import word_error_rate, \\\n",
    "    post_process_predictions, post_process_transcripts\n",
    "\n",
    "greedy_hypotheses = post_process_predictions(\n",
    "    evaluated_tensors[1], labels)\n",
    "\n",
    "references = post_process_transcripts(\n",
    "    evaluated_tensors[2], evaluated_tensors[3], labels)\n",
    "\n",
    "wer = word_error_rate(hypotheses=greedy_hypotheses, references=references)\n",
    "print(\"*** WER: {:.2f} ***\".format(wer * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greedy_hypotheses[10])\n",
    "print(references[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greedy_hypotheses[20])\n",
    "print(references[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
